Figure out $P(Y|X)$ by using $P(X,Y)$. i.e., by using $P(X|Y)P(X)$ and relating via [Bayes' Theorem](Fundamental%20Concepts/Statistics/Bayes'%20Theorem.md) ($P(Y)$ is irrelevant - see [NBC (Naive Bayes Classifier)](Algorithms/Models/Supervised/General/NBC%20(Naive%20Bayes%20Classifier).md). This entails modeling how the data $X$ is generated by the $Y$ we're trying to predict - i.e, we want to understand how $Y$ generates $X$.

Learns the distributions, and predicts the probability that given each possible distribution, this observation would come from it.

Usually needs some assumptions on what the distribution is.
For example:
- [NBC (Naive Bayes Classifier)](Algorithms/Models/Supervised/General/NBC%20(Naive%20Bayes%20Classifier).md) assumes that given a certain class, all of the features are independent.
- [LDA (Linear Discriminant Analysis)](Algorithms/Models/Supervised/General/LDA%20(Linear%20Discriminant%20Analysis).md) assumes all classes are Gaussian distributions with the same covariance as each other (and different means).
- [QDA (Quadratic Discriminant Analysis)](Algorithms/Models/Supervised/General/QDA%20(Quadratic%20Discriminant%20Analysis).md) assumes all classes are Gaussian distributions.